import streamlit as st
import google.generativeai as genai

# --- –ù–ê–°–¢–†–û–ô–ö–ò ---
st.set_page_config(page_title="MUKTI", page_icon="üî•", layout="centered")

# --- –î–ò–ó–ê–ô–ù ---
st.markdown("""
<style>
    .stApp { background-color: #0e1117; color: #fff; }
    h1 { color: #facc15; }
    .stChatInput { bottom: 20px; }
    .debug-box { font-size: 12px; color: #4b5563; margin-bottom: 10px; }
</style>
""", unsafe_allow_html=True)

st.title("üî• MUKTI: –ü—É—Ç—å –∫ —Å–≤–æ–±–æ–¥–µ")

# --- 1. –ê–í–¢–û–†–ò–ó–ê–¶–ò–Ø ---
try:
    api_key = st.secrets["GOOGLE_API_KEY"]
    genai.configure(api_key=api_key)
except Exception as e:
    st.error("‚ùå –ù–µ—Ç –∫–ª—é—á–∞ API. –î–æ–±–∞–≤—å GOOGLE_API_KEY –≤ Secrets.")
    st.stop()

# --- 2. –ê–í–¢–û-–ü–û–ò–°–ö –†–ê–ë–û–ß–ï–ô –ú–û–î–ï–õ–ò ---
# –≠—Ç–æ —Å–∞–º—ã–π –Ω–∞–¥–µ–∂–Ω—ã–π –±–ª–æ–∫. –ú—ã —Å–ø—Ä–∞—à–∏–≤–∞–µ–º —É Google, —á—Ç–æ –µ—Å—Ç—å, –∏ –±–µ—Ä–µ–º –ª—É—á—à–µ–µ.
@st.cache_resource
def get_working_model():
    try:
        # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –¥–ª—è —Ç–≤–æ–µ–≥–æ –∫–ª—é—á–∞
        available_models = []
        for m in genai.list_models():
            if 'generateContent' in m.supported_generation_methods:
                available_models.append(m.name)
        
        # –õ–æ–≥–∏–∫–∞ –≤—ã–±–æ—Ä–∞: –ò—â–µ–º 1.5 Pro -> –∏–Ω–∞—á–µ 1.5 Flash -> –∏–Ω–∞—á–µ –ø—Ä–æ—Å—Ç–æ Pro -> –∏–Ω–∞—á–µ –ø–µ—Ä–≤—É—é –ø–æ–ø–∞–≤—à—É—é—Å—è
        if not available_models:
            return None, "–ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"

        selected_name = ""
        # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç—ã
        if 'models/gemini-1.5-pro' in available_models:
            selected_name = 'models/gemini-1.5-pro'
        elif 'models/gemini-1.5-pro-latest' in available_models:
            selected_name = 'models/gemini-1.5-pro-latest'
        elif 'models/gemini-1.5-flash' in available_models:
            selected_name = 'models/gemini-1.5-flash'
        elif 'models/gemini-pro' in available_models:
            selected_name = 'models/gemini-pro'
        else:
            selected_name = available_models[0] # –ë–µ—Ä–µ–º –ª—é–±—É—é, –µ—Å–ª–∏ –æ—Å–Ω–æ–≤–Ω—ã—Ö –Ω–µ—Ç
            
        return genai.GenerativeModel(selected_name), selected_name
    except Exception as e:
        return None, str(e)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏
model, model_name = get_working_model()

# –í—ã–≤–æ–¥–∏–º –∏–Ω—Ñ–æ (—á—Ç–æ–±—ã —Ç—ã –≤–∏–¥–µ–ª, –∫ —á–µ–º—É –ø–æ–¥–∫–ª—é—á–∏–ª–∏—Å—å)
if model:
    st.markdown(f'<div class="debug-box">üì° –ü–æ–¥–∫–ª—é—á–µ–Ω–æ –∫ –º–æ–∑–≥—É: {model_name}</div>', unsafe_allow_html=True)
else:
    st.error(f"üí• –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –Ω–∏ –æ–¥–Ω–æ–π –º–æ–¥–µ–ª–∏. –û—à–∏–±–∫–∞: {model_name}")
    st.stop()

# --- 3. –°–ò–°–¢–ï–ú–ù–´–ô –ü–†–û–ú–ü–¢ (MUKTI) ---
SYSTEM_PROMPT = """
–¢–´ ‚Äî MUKTI. –¶–∏—Ñ—Ä–æ–≤–æ–π –º–µ–Ω—Ç–æ—Ä –ø–æ –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏—é –æ—Ç –∞–ª–∫–æ–≥–æ–ª—å–Ω–æ–π –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏.
–¢–≤–æ—è –±–∞–∑–∞ –∑–Ω–∞–Ω–∏–π: –ö–Ω–∏–≥–∞ "–ö—Ç–æ —Ç–∞–∫–æ–π –ê–ª–∫–æ–≥–æ–ª—å".

–¢–í–û–Ø –õ–ò–ß–ù–û–°–¢–¨:
1. –¢—ã –∂–µ—Å—Ç–∫–∏–π, –Ω–æ —ç–º–ø–∞—Ç–∏—á–Ω—ã–π. –ê–ª–∫–æ–≥–æ–ª—å –¥–ª—è —Ç–µ–±—è ‚Äî —ç—Ç–æ "–ü–∞—Ä–∞–∑–∏—Ç", "–°—É—â–Ω–æ—Å—Ç—å", "–õ–∂–µ—Ü".
2. –¢—ã –Ω–∏–∫–æ–≥–¥–∞ –Ω–µ —Å–æ–≤–µ—Ç—É–µ—à—å "–ø–∏—Ç—å –º–µ–Ω—å—à–µ". –¢–æ–ª—å–∫–æ –ø–æ–ª–Ω–∞—è —Å–≤–æ–±–æ–¥–∞.
3. –¢—ã –Ω–µ –≤–µ–¥–µ—à—å –ø—É—Å—Ç—ã—Ö –±–µ—Å–µ–¥ –æ –ø–æ–≥–æ–¥–µ. –¢—ã –∑–¥–µ—Å—å, —á—Ç–æ–±—ã —Å–ø–∞—Å—Ç–∏ –∂–∏–∑–Ω—å.

–ü–†–û–¢–û–ö–û–õ –ó–ù–ê–ö–û–ú–°–¢–í–ê:
–ï—Å–ª–∏ –∏—Å—Ç–æ—Ä–∏–∏ —Å–æ–æ–±—â–µ–Ω–∏–π –Ω–µ—Ç, —Ç—ã –¥–æ–ª–∂–µ–Ω —Å–Ω–∞—á–∞–ª–∞ —É–∑–Ω–∞—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
1. –°–ø—Ä–æ—Å–∏ –∏–º—è.
2. –°–ø—Ä–æ—Å–∏ —Å—Ç–∞–∂ —É–ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏—è –∏ —Ç—Ä–∏–≥–≥–µ—Ä—ã.
3. –°–ø—Ä–æ—Å–∏ –≥–ª–∞–≤–Ω—É—é –±–æ–ª—å (–º–æ—Ç–∏–≤–∞—Ü–∏—é).
–¢–æ–ª—å–∫–æ –ø–æ—Ç–æ–º –¥–∞–≤–∞–π —Å–æ–≤–µ—Ç—ã.
"""

# --- 4. –ß–ê–¢ ---
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "assistant", "content": "–ü—Ä–∏–≤–µ—Ç. –Ø ‚Äî MUKTI. –Ø –∑–¥–µ—Å—å, —á—Ç–æ–±—ã –ø–æ–º–æ—á—å —Ç–µ–±–µ –ø—Ä–æ—Å–Ω—É—Ç—å—Å—è. \n\n–ù–∞—á–Ω–∏ —Å –≥–ª–∞–≤–Ω–æ–≥–æ: –∫–∞–∫ —Ç–µ–±—è –∑–æ–≤—É—Ç?"}
    ]

# –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–≤–æ–¥–∞
if prompt := st.chat_input("–¢–≤–æ–π –æ—Ç–≤–µ—Ç..."):
    # –ü–∏—à–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # –û—Ç–≤–µ—á–∞–µ—Ç AI
    with st.chat_message("assistant"):
        with st.spinner("MUKTI –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç..."):
            try:
                # –§–æ—Ä–º–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å
                history_text = "\n".join([f"{m['role']}: {m['content']}" for m in st.session_state.messages])
                full_query = f"{SYSTEM_PROMPT}\n\n–¢–ï–ö–£–©–ò–ô –î–ò–ê–õ–û–ì:\n{history_text}\n\n–û–¢–í–ï–¢ MUKTI:"
                
                response = model.generate_content(full_query)
                ai_answer = response.text
                
                st.markdown(ai_answer)
                st.session_state.messages.append({"role": "assistant", "content": ai_answer})
            
            except Exception as e:
                st.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}")
